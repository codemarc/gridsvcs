{
  "name": "apache",
  "title": "apache",
  "href1": "https://apache.org",
  "href2": "*/settings",
  "links": [
    {
      "pre1": " projects by » ",
      "name1": "name",
      "href1": "https://projects.apache.org/projects.html?name",
      "post1": " |",
      "name2": "lang",
      "href2": "https://projects.apache.org/projects.html?language",
      "post2": " | ",
      "name3": "cat",
      "href3": "https://projects.apache.org/projects.html?category"
    },
    {
      "name1": "- classics  ",
      "title1": "Apache projects that have been around for a long time."
    },
    {
      "pre1": " ",
      "name1": "http",
      "href1": "https://httpd.apache.org/",
      "title1": "The Apache HTTP Server Project is an effort to develop and maintain an open-source HTTP server for modern operating systems including UNIX and Windows NT. The goal of this project is to provide a secure, efficient and extensible server that provides HTTP services in sync with the current HTTP standards.",
      "pre2": " ",
      "name2": "tomcat",
      "href2": "https://tomcat.apache.org/",
      "title2": "The Apache Tomcat software is an open source implementation of the Java Servlet, JavaServer Pages, Java Expression Language and Java WebSocket technologies. The Java Servlet, JavaServer Pages, Java Expression Language and Java WebSocket specifications are developed under the Java Community Process.",
      "pre3": " ",
      "name3": "kafka",
      "href3": "https://kafka.apache.org/",
      "title3": "Apache Kafka is an open-source distributed event streaming platform used by thousands of companies for high-performance data pipelines, streaming analytics, data integration, and mission-critical applications.",
      "pre4": " ",
      "name4": "hadoop",
      "href4": "https://hadoop.apache.org/",
      "title4": "The Apache Hadoop software library is a framework that allows for the distributed processing of large data sets across clusters of computers using simple programming models. It is designed to scale up from single servers to thousands of machines, each offering local computation and storage."
    },
    {
      "pre1": "  ",
      "name1": "spark",
      "href1": "https://spark.apache.org/",
      "title1": "Apache Spark is a multi-language engine for executing data engineering, data science, and machine learning on single-node machines or clusters.",
      "pre2": " ",
      "name2": "lucene",
      "href2": "https://lucene.apache.org/",
      "title2": "Apache Lucene is a free and open-source information retrieval software library, originally written completely in Java by Doug Cutting. It is supported by the Apache Software Foundation and is released under the Apache Software License.",
      "pre3": " ",
      "name3": "maven",
      "href3": "https://maven.apache.org/",
      "title3": "Apache Maven is a software project management and comprehension tool. Based on the concept of a project object model (POM), Maven can manage a project's build, reporting and documentation from a central piece of information.",
      "pre4": " ",
      "name4": "ant",
      "href4": "https://ant.apache.org/",
      "title4": "Apache Ant is a Java library and command-line tool whose mission is to drive processes described in build files as targets and extension points dependent upon each other. The main known usage of Ant is the build of Java applications."
    },
    {
      "name1": "- others",
      "title1": "Apache projects address interesting technology."
    },
    {
      "pre1": " ",
      "name1": "couchdb",
      "href1": "https://couchdb.apache.org/",
      "title1": "Apache CouchDB is a database that uses JSON for documents, an HTTP API, and designed to be accessible via a web browser. It allows for data replication across multiple nodes for robustness and availability, and has a document update model rather than direct overwriting for conflict detection and resolution.",
      "name2": "flume",
      "href2": "https://flume.apache.org/",
      "title2": "Apache Flume is a distributed, reliable, and available service for efficiently collecting, aggregating, and moving large amounts of log data. It has a simple and flexible architecture based on streaming data flows. It is robust and fault tolerant with tunable reliability mechanisms and many failover and recovery mechanisms. It uses a simple extensible data model that allows for online analytic application.",
      "name3": "ambari",
      "hre3": "https://ambari.apache.org/",
      "title3": "Apache Ambari is a software project designed to make Hadoop management simpler by developing software for provisioning, managing, and monitoring Apache Hadoop clusters. Ambari provides an intuitive collection of operator tools and a robust set of APIs that hide the complexity of Hadoop, simplifying the operation of clusters.",
      "name4": "airflow",
      "href4": "https://airflow.apache.org/",
      "title4": "Apache Airflow is an open-source workflow management platform. It started at Airbnb in October 2014 as a solution to manage the company's increasingly complex workflows. From monitoring data pipelines to provisioning large-scale data processing resources in a cloud, Airflow is becoming a highly efficient way of writing, scheduling and monitoring workflows."
    },
    {
      "pre1": "   ",
      "name1": "parquet",
      "href1": "https://parquet.apache.org/",
      "title1": "Apache Parquet is a columnar storage format that enables efficient storage and retrieval of large analytic datasets. It uses the record shredding and assembly algorithm described in the Dremel paper by Google.",
      "post1": " ",
      "name2": "flink",
      "href2": "https://flink.apache.org/",
      "title2": "Apache Flink is a framework and distributed processing engine for stateful computations over unbounded and bounded data streams. Flink has been designed to run in all common cluster environments, perform computations at in-memory speeds and at any scale.",
      "post2": " ",
      "name3": "thrift",
      "href3": "https://thrift.apache.org/",
      "title3": "Apache Thrift is a software framework for scalable cross-language services development. It combines a software stack with a code generation engine to build services that work efficiently and seamlessly between C++, Java, Python, PHP, Ruby, Erlang, Perl, Haskell, C#, Cocoa, JavaScript, Node.js, Smalltalk, OCaml and Delphi and other languages.",
      "post3": " ",
      "name4": "avro",
      "href4": "https://avro.apache.org/",
      "title4": "Apache Avro is a data serialization system which provides rich data structures, a compact, fast, binary data format, a container file to store persistent data, and remote procedure call (RPC)."
    },
    {
      "pre1": "ㅤ"
    },
    {
      "pre1": "ㅤ"
    }
  ]
}